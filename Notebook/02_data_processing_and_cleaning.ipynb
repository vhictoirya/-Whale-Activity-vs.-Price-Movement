{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d83f7360",
   "metadata": {},
   "source": [
    "#### Loading saved data from joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a59ce04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: c:\\Users\\FFFO CASHIER PT\\OneDrive\\Desktop\\Mini capstone project\\Notebook\n",
      "Files in target folder: ['dune_data.pkl', 'wrapped-bitcoin_prices.pkl']\n"
     ]
    }
   ],
   "source": [
    "# To get the folder where the script is running\n",
    "import os\n",
    "\n",
    "print(\"Current directory:\", os.getcwd())\n",
    "\n",
    "folder = r'C:/Users/FFFO CASHIER PT/OneDrive\\Desktop/Mini Capstone project/database'\n",
    "print(\"Files in target folder:\", os.listdir(folder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6e291da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "# Load price data from joblib file\n",
    "df_price = joblib.load(r'C:/Users/FFFO CASHIER PT/OneDrive/Desktop/Mini Capstone project/database/wrapped-bitcoin_prices.pkl')\n",
    "\n",
    "# Load whale transfer data from joblib file\n",
    "df_whale = joblib.load(r'C:/Users/FFFO CASHIER PT/OneDrive/Desktop/Mini Capstone project/database/dune_data.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c050f0c",
   "metadata": {},
   "source": [
    "### Load & Prepare Price Data (df_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e58866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['timestamp', 'price'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check column names\n",
    "print(df_price.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc667e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=91, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(df_price.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9f5e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price.index.name = 'timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3839f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp to datetime \n",
    "df_price['timestamp'] = pd.to_datetime(df_price['timestamp'])\n",
    "\n",
    "# Set timestamp as index\n",
    "df_price.set_index('timestamp', inplace=True)\n",
    "\n",
    "# Now set daily frequency and forward fill missing days\n",
    "df_price = df_price.asfreq('D', method='ffill')\n",
    "\n",
    "# Reset index if you want 'timestamp' back as a column\n",
    "df_price = df_price.reset_index()\n",
    "\n",
    "# Create 'date' column from timestamp for merging\n",
    "df_price['date'] = df_price['timestamp'].dt.floor('D')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b4c829",
   "metadata": {},
   "source": [
    "### Load & Prepare Whale Data (df_whale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7e4f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     receiver  \\\n",
      "0  0x9a62db4c17146172c0b88e7e439df169a0f93e0e   \n",
      "1  0xa4b9569bf942c3aad23c0c2d322fe4aff8e1bf30   \n",
      "2  0x2a49eae5cca3f050ebec729cf90cc910fadaf7a2   \n",
      "3  0xd49a3ff72739e3fe9537645acad3ba3e65f6690d   \n",
      "4  0x51c72848c68a965f66fa7a88855f9f7784502a7f   \n",
      "\n",
      "                                       sender                         time  \\\n",
      "0  0xa3a7b6f88361f48403514059f1f16c8e78d60eec  2025-08-06 18:56:11.000 UTC   \n",
      "1  0xd49a3ff72739e3fe9537645acad3ba3e65f6690d  2025-08-06 18:51:35.000 UTC   \n",
      "2  0xfa8c996e158b80d77fbd0082bb437556a65b96e0  2025-08-06 18:32:23.000 UTC   \n",
      "3  0x39c1cc6e689f001567f80b279277f921ce88e6a5  2025-08-06 18:29:11.000 UTC   \n",
      "4  0xe8f7c89c5efa061e340f2d2f206ec78fd8f7e124  2025-08-06 18:28:11.000 UTC   \n",
      "\n",
      "      usd_value  \n",
      "0  1.557364e+05  \n",
      "1  2.450904e+06  \n",
      "2  1.225749e+05  \n",
      "3  2.454708e+06  \n",
      "4  1.368616e+05  \n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Load the raw whale data (likely a list of dicts)\n",
    "rows = joblib.load(r'C:/Users/FFFO CASHIER PT/OneDrive/Desktop/Mini Capstone project/database/dune_data.pkl')\n",
    "\n",
    "# Convert it into a DataFrame\n",
    "df_whale = pd.DataFrame(rows)\n",
    "\n",
    "# Preview\n",
    "print(df_whale.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cf30c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each transaction is counted once for sender and once for receiver\n",
    "# So this way the whale_volume and whale_count wont be assumed to be 0\n",
    "\n",
    "df_sender = df_whale[['time', 'usd_value']].copy()\n",
    "df_sender['role'] = 'sender'\n",
    "\n",
    "df_receiver = df_whale[['time', 'usd_value']].copy()\n",
    "df_receiver['role'] = 'receiver'\n",
    "\n",
    "# Combine both\n",
    "df_whale_dual = pd.concat([df_sender, df_receiver], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2119e680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "print(df_whale_dual['time'].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63432892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time is already in datetime, convert it directly\n",
    "\n",
    "df_whale_dual['time'] = pd.to_datetime(df_whale_dual['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45acb990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Floor time to daily to match price granularity\n",
    "df_whale_dual['date'] = df_whale_dual['time'].dt.floor('D')\n",
    "\n",
    "# Group by date\n",
    "whale_daily = df_whale_dual.groupby('date').agg(\n",
    "    whale_volume=('usd_value', 'sum'),\n",
    "    whale_count=('usd_value', 'count')  # counts both senders and receivers\n",
    ").reset_index()\n",
    "\n",
    "# Rename columns\n",
    "whale_daily.columns = ['date', 'whale_volume', 'whale_count']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c47b381",
   "metadata": {},
   "source": [
    "### Merging Price movement and Whale Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0ea180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-09 00:00:00 to 2025-08-06 00:00:00\n",
      "2025-06-07 00:00:00 to 2025-08-06 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Checking for the unique dates in both dataframes\n",
    "\n",
    "print(df_price['date'].min(), \"to\", df_price['date'].max())\n",
    "print(whale_daily['date'].min(), \"to\", whale_daily['date'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733d11d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n",
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Confirming the data types of date columns\n",
    "\n",
    "print(df_price['date'].dtype)\n",
    "print(whale_daily['date'].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aec21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  whale_volume  whale_count\n",
      "0 2025-06-07  3.447736e+08          114\n",
      "1 2025-06-08  9.437152e+08          894\n",
      "2 2025-06-09  3.807983e+09         2752\n",
      "3 2025-06-10  2.099090e+09         2562\n",
      "4 2025-06-11  1.847041e+09         1958\n",
      "                      date  whale_volume  whale_count\n",
      "count                   61  6.100000e+01    61.000000\n",
      "mean   2025-07-07 00:00:00  2.992789e+09  1978.295082\n",
      "min    2025-06-07 00:00:00  3.447736e+08   114.000000\n",
      "25%    2025-06-22 00:00:00  1.673295e+09  1332.000000\n",
      "50%    2025-07-07 00:00:00  2.348700e+09  1958.000000\n",
      "75%    2025-07-22 00:00:00  3.501512e+09  2562.000000\n",
      "max    2025-08-06 00:00:00  1.288021e+10  3804.000000\n",
      "std                    NaN  2.224794e+09   807.369460\n"
     ]
    }
   ],
   "source": [
    "# Preview the whale data before merge to check if values are non-zero\n",
    "\n",
    "print(whale_daily.head())\n",
    "print(whale_daily.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6c57df88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    timestamp          price       date  whale_volume  whale_count\n",
      "85 2025-08-02  113251.979613 2025-08-02  1.074155e+10       1800.0\n",
      "86 2025-08-03  112513.216187 2025-08-03  4.898928e+09       1048.0\n",
      "87 2025-08-04  114185.282407 2025-08-04  5.091967e+09       1650.0\n",
      "88 2025-08-05  114923.152934 2025-08-05  5.274239e+09       1740.0\n",
      "89 2025-08-06  114106.509533 2025-08-06  3.175733e+09        996.0\n"
     ]
    }
   ],
   "source": [
    "# Merge price and whale daily data on 'date'\n",
    "df_merged = pd.merge(df_price, whale_daily, on='date', how='left')\n",
    "\n",
    "# Fill NaN values in whale data with 0 (for days without whale activity)\n",
    "df_merged['whale_volume'] = df_merged['whale_volume'].fillna(0)\n",
    "df_merged['whale_count'] = df_merged['whale_count'].fillna(0)\n",
    "\n",
    "# Final structure\n",
    "print(df_merged.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0f4de505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     datetime          price  price_change_pct  whale_tx_count  \\\n",
      "85 2025-08-02  113251.979613         -2.050064          1800.0   \n",
      "86 2025-08-03  112513.216187         -0.652318          1048.0   \n",
      "87 2025-08-04  114185.282407          1.486107          1650.0   \n",
      "88 2025-08-05  114923.152934          0.646205          1740.0   \n",
      "89 2025-08-06  114106.509533         -0.710600           996.0   \n",
      "\n",
      "    whale_tx_volume  \n",
      "85     1.074155e+10  \n",
      "86     4.898928e+09  \n",
      "87     5.091967e+09  \n",
      "88     5.274239e+09  \n",
      "89     3.175733e+09  \n"
     ]
    }
   ],
   "source": [
    "# Calculate price percentage change\n",
    "df_merged = df_merged.sort_values('date')\n",
    "df_merged['price_change_pct'] = df_merged['price'].pct_change() * 100\n",
    "\n",
    "# Rename columns\n",
    "df_merged.rename(columns={\n",
    "    'date': 'datetime',\n",
    "    'whale_count': 'whale_tx_count',\n",
    "    'whale_volume': 'whale_tx_volume'\n",
    "}, inplace=True)\n",
    "\n",
    "# Select columns\n",
    "final_df = df_merged[['datetime', 'price', 'price_change_pct', 'whale_tx_count', 'whale_tx_volume']]\n",
    "\n",
    "print(final_df.tail())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonK (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
